\chapter{State of the Art}

This chapter describes how the company handles the required processes and takes advantages of the technologies in order to develop the software that runs on the industrial devices and the cloud platform. It also details which technologies and methodologies are used to develop the software in the company. This chapter represents the context in which the project started.

From now on, the first plural person conjugation is used to refer to the individual experience.

\section{Company}

The company is located in the province of Verona in Italy. The factory building formally includes the main company, which is the one that designs and produces the industrial devices, and another company.

The latter is the business where we are enrolled for the internship; it is in charge of the development of cloud platform that allows these devices to become domotic, that is industrial automation, in order to send and receive data from the cloud, to be able to interact with the device remotely and to be able to monitor the status of the device. The software is a built-in service running on the hardware, and all the data are collected and sent to the cloud through the company's servers.

Since the businesses are part of the same holding group, they share administrative resources and also technical resources. From now on, we refer to the main (or first) company talking about standards, regulations and devices, and to the (our) second one talking about the software and the cloud.

\subsection{Software company organization}

The cloud management software, developed by the second company, is composed of five main layers and it is managed by five different teams:
\begin{itemize}
  \item \textbf{Device data}: it should make friendly the adoption of the platform and it handles the cloud lifecycle of a device, by managing the device registration and the handling of the collected data to being able to create flexible dashboards and reports;
  \item \textbf{VPN}: it handles the connection to a device through a VPN and it is in charge of the security of the connection;
  \item \textbf{Apps}: the work of the apps team is to increase the value of the platform, by allowing third parties to integrate their services with the platform and by creating apps that can be installed on the devices. Customers can craft their own apps by using the provided \textit{Software Development Kit} (SDK), that is a set of tools and documentation;
  \item \textbf{Core}: it is the core of the platform and it in responsible for the provided backend REST APIs mainly used for the frontend website. It also handles the management of the user via a custom \textit{IDentity Provider} (IDP);
  \item \textbf{Platform}: last but not least, the platform team orchestrate all the infrastructure needed to run the services and it is in charge of the deployment of the services on the cloud. It is also responsible for the monitoring of the services and for the security of the development lifecycle and deployment process.
\end{itemize}

The cloud software is developed using the microservices architecture, that is a design pattern that structures an application as a collection of loosely coupled services. Services can be developed, deployed and scaled independently.

We were virtually part of the apps team, and we were in charge of developing a scanning tool that can be used to check the security of the devices powered by the cloud management software and to report the potential issues to the customer.

\section{Initial design}

Under the hood, every PLC is powered by a custom Linux distribution, provided by \textit{Yocto Project}, an open-source collaboration project that helps developers create custom Linux-based systems regardless of the hardware architecture~\cite{yocto-project}, developed by the internal \textit{Research \& Development} (R\&D) team.

In order to be able to make the device interact with the industrial machines, the company provides a proprietary IDE software, needed to scratch projects and deploy them on the device. This software lets the user define the inputs and outputs of the device and the logic that will be executed on the device. In example, the user can define a trigger, an alarm that will be raised when a certain condition is met, a personalized handling of the data received by the many supported protocols and so on.

Furthermore, the same IDE is used to draw the graphical interface that will be displayed on the HMI and to define the behaviour of the interface itself.\\
The graphical interface is composed of widgets, that are the building blocks of the interface. The user can define the position of the widgets, their size, their colour and their behaviour. The widgets can be buttons, labels, images, graphs or custom-defined ones.

The setup with their IDE software is strictly related to the device interacting with the industrial machines, and it is not the focus of the internship project. The focus is on the device itself, and on the software that runs on it.

Given that, at the beginning stages, our scanning tool could not be installed and released as a firmware update for the devices, because that would require a modification of the R\&D team's workflow, we decided to develop the scanning tool as an executable binary that can be run on the device itself. It is a \textit{command-line interface} (CLI) tool able to perform the scan and report an output to the user. Then, the user will be able to fix the issues by itself, by interacting with the device settings.

\section{Device settings}

The PLC backend provides a web interface that can be used to view and change the system settings of the device. The user can change the network settings, set the datetime, set the management user password, manage the startup of the services like the SSH server and much more. The HMI touchscreen, through dedicated gestures, lets the user directly interact locally with the onboard interface, otherwise it is possible to reach it by connecting to the local webserver exposed at the device's network address. \\
Client and server, respectively the graphical interface and the backend, are independent of each other; the web interface is powered by REST APIs.

For the internship project, we will take advantage of the REST APIs to retrieve the status of the device and to potentially change its settings. Internally to the company, the APIs are documented with the \textit{OpenAPI Specification}, formerly \textit{Swagger Specification}, which is an API description format that depicts the endpoints, the parameters, the responses, the authentication needed to call them and licenses or other information. The Swagger file can be visualized through the Swagger UI, a web interface that renders OpenAPI definitions as interactive documentation.~\cite{openapi-swagger}

We can devise two different scenarios: API calls made by a remote host over a network and API calls made by the local host. In the first case, the TLS protocol secures the communication using the public-key authentication first, and then the APIs are protected by a basic authentication, that is the client must provide the username of a management account and its related password. In the second case, the webserver listens as read-only over a port accessible by the same host only with no further authentication needed. Given that the scanning tool will be run on the device itself, we will take advantage of the second case. From the security side, the combination of read-only access and physical access to be able to call unauthenticated endpoints is considered secure.

\section{\textit{Go} programming language}
\label{sec:go-lang}

\textit{Go} is an open-source programming language supported by Google, designed for building simple, reliable and efficient software. It is statically typed, compiled and syntactically similar to C, with the added benefits of built-in concurrency management, garbage collection, memory safety, a rich standard library and lot of community packages. Go is widely used in cloud computing and web development due to its simplicity, performance and scalability.~\cite{go-lang-site}~\cite{go-lang-wikipedia}\\
Go was released in 2007 by Google, and at the time of writing it is at version \texttt{1.22}.

Go's standard library provides comprehensive support for networking, encryption and concurrency~\cite{go-package-std}. The built-in packages for HTTP, TLS and JSON processing simplify the implementation of RESTful APIs, secure communication channels and data serialization/deserialization, respectively. If additional functionalities are required, the language supports third-party packages through the Go module system; in order to download a custom package, the developer simply references it in the code via the link to the repository and the Go compiler will automatically download and install it.

Go also offers a robust testing framework to write unit tests and benchmarks to ensure the reliability and performance of their code.

Another point in favor is the efficiency of the language. Go is compiled into machine code, which makes it faster than interpreted languages like Python. The language's garbage collection mechanism automatically manages memory allocation and deallocation, reducing the risk of memory leaks and improving the overall performance of the application. The language is more than a full order of magnitude faster than Python, with a smaller memory footprint and faster execution times.~\cite{go-lang-performance}

One of the main reasons for choosing Go for the internship project is its versatility in building executable binaries for multiple platforms, including Windows, macOS and Linux. Go's cross-compilation capabilities allow the developers to build binaries for different operating systems and architectures from a single codebase, simplifying the deployment process and ensuring compatibility across various platforms. Given that industrial devices run on different architectures and operating systems, the ability to build cross-platform binaries is essential. The language natively supports the binaries compilation for over 50 combinations of operating systems and architectures~\cite{go-lang-compilation-combo}; given that the majority of the company's devices run either on \texttt{Arm 32bit} or \texttt{Arm 64bit} or \texttt{x86 64bit} architectures, the Go compiler can generate the executables for these architectures with no further configuration needed.

\section{Adopted technologies}

Referring to~\cref{cha:background}, the company take advantage of many technologies to develop the software that runs on the industrial devices and on the cloud platform. We are going to describe the most relevant software used in the company.

\subsection{Security vulnerabilities scan}

The company uses \textit{Snyk}\footnote{\url{https://snyk.io}} to scan the software for vulnerabilities and receive alerts for security issues in the code. Snyk is a security company that provides a platform that enables developers to find and fix vulnerabilities in their code and dependencies. Snyk integrates with popular development tools and workflows, making it easy for developers to identify and address security issues early in the development process.

It offers a range of security tools, including vulnerability scanning, dependency monitoring and container security. The platform provides real-time alerts and recommendations for fixing security issues, helping developers to secure their applications and prevent security breaches. It also offers a vulnerability database that contains information about common security vulnerabilities and their impact on software applications.

\subsection{Deployment of the microservices}

Specific software are used to manage the entire infrastructure of the cloud platform, from the development and testing to the deployment and monitoring of the services.

\subsubsection{Docker}

The company uses \textit{Docker}\footnote{\url{https://www.docker.com}} to create, deploy and run containers. Docker is an application that allows developers to build, package and run applications as containers.

Docker itself enables the user to instantiate a single container at time from an image, that is a series of instructions that defines the environment of the container, starting from the base operating system up to all the steps needed to install the final software.

Docker containers can be deployed on any platform that supports Docker, including Linux, Windows and macOS. The company uses Linux as the operating system for the cloud platform, and the containers are deployed on a Kubernetes cluster.

\subsubsection{Kubernetes}

The containers can be managed by \textit{Kubernetes}\footnote{\url{https://kubernetes.io}}, also known as \textit{K8s}, an open-source container orchestration platform that provides a platform for automating the deployment, scaling and operations of application containers across clusters of hosts. It works with a range of container tools, including Docker. Kubernetes was originally developed by Google, and in 2014 it has been open-sourced.~\cite{kubernetes-overview}

Kubernetes is a powerful tool that allows the user to manage the containers in a declarative way, that is the user declares the desired state of the system, and Kubernetes takes care of the rest. The user can define the number of replicas of a container, the resources needed by the container, the network configuration, the storage configuration and much more. Kubernetes will take care of the deployment of the containers, the scaling of the containers, the recovery of the containers in case of failure and the load balancing of the containers.

An instance of Kubernetes is called a \textit{cluster} and it is composed of \textit{master nodes} and one or more \textit{worker nodes}. The master node is in charge of the orchestration of the containers, while the worker nodes are in charge of running the containers. The master node is composed of the API server, the scheduler, the controller manager and \textit{etcd}, that is a distributed key-value store used to store the state of the cluster. The worker nodes are composed of the \textit{kubelet}, which is the agent that runs on each node and is responsible for the communication between the master node and the worker node and the \textit{kube-proxy}, that is a network proxy that runs on each node and maintains network rules.

Every action towards the cluster is performed through the API calls to the API server, that is the entry point for the cluster. The user can interact with the cluster through the \textit{kubectl} command-line tool, that is the Kubernetes command-line tool, or through the many available third-party software that interact with the Kubernetes API.

\subsubsection{Helm}

\textit{Helm}\footnote{\url{https://helm.sh}} is a package manager for Kubernetes that allows the user to define, install and upgrade Kubernetes applications. Helm uses a packaging format called \textit{charts}, that are a collection of files that describe a set of Kubernetes resources. Helm charts can be used to define the resources needed by the application, the dependencies, the configuration and the hooks that should be executed during the installation.

Helm can be used to deploy the microservices on the Kubernetes cluster.

\subsubsection{CI/CD pipeline}

A series of flows can be used to automate the building, testing and deployment of the software.

Once the code is pushed to the main or to the developer branch of the repository, the CI tool, hosted on the GitHub Actions\footnote{\url{https://github.com/features/actions}}, automatically runs the tests and, if successful, builds the image for \texttt{amd64} and \texttt{arm64} and it pushes the image to a private container registry, hosted on Google Artifact Registry\footnote{\url{https://cloud.google.com/artifact-registry/docs}}.

\subsection{Scrum}

The company takes advantage of the Scrum framework to manage the development of the cloud software, via the \textit{Jira} suite\footnote{\url{https://www.atlassian.com/software/jira}}, a project management tool developed by Atlassian. The platform is used to manage the product and the sprint backlog, the epics and the stories and to track the progress of the team.

The team uses a board with five columns: \textit{To Do}, \textit{In Progress}, \textit{Standby}, \textit{In review} and \textit{Done}. The stories are moved from one column to another as the work progresses. In addition to the usual columns, as defined by the framework, the third column contains the stories that are blocked by some external factor and the fourth column contains those stories that are in the testing phase. Eventually, the stories are moved to the last column.

We created a new Epic for the scanning tool and we filled it with the stories that we thought were needed to develop the tool. In this specific case, the sprint period was a month because of the internship duration. At the end of the sprint, the product backlog contained some pending stories, because of the limited time and the ongoing updating of the priorities. The daily scrum was achieved by a quotidian quick meeting with the business tutor, where we keep him updated on the progress of the stories. Of course, new stories were added to the backlog and some of them were de-prioritized.

\section{Platform applications}
\label{sec:platform-applications}

The cloud management platform has an applications store where the developers can upload their web \textit{apps}.

The scaffolding of the web app is provided by a public NPM package. It is a drafted working application, so the developer can start to develop the app without the need to set up the project from scratch. Furthermore, it contains the necessary base configuration files to deploy the app to the platform. The app has to be deployed in a dedicated Kubernetes namespace in a cluster, and later it has to be pushed to the app store by using the public platform APIs.

A scaffolding app is composed of two layers: the frontend, which is the user interface, and the backend, which is the logic of the application. The frontend is written in VueJS\footnote{\url{https://vuejs.org}} and the backend is written in NestJS\footnote{\url{https://nestjs.com}}, a progressive Node.js framework. The former is a web application that the user can access from the cloud platform and the latter manages REST APIs.

% As a educational project during the internship, we also have to develop the platform app for the scanning tool. We effectively setup the backend to be used as a proxy, and the frontend is a simple page that 