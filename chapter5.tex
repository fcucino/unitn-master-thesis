\chapter{System Implementation}

This chapter describes how the system is actually being implemented.

\section{Go language interfaces}

The Go programming language provides a powerful feature called interfaces. An interface is a collection of method signatures that a type, like a struct, can implement. Interfaces allow to define a set of methods that a type must implement to be considered an instance of that interface. This allows to write code that is more flexible, especially for testing purposes.

We setup each one of the checks as a separate interface, so that we can easily test them in isolation and also to make it easier to manage the codebase and add new checks in the future, like if they are modules that can be added or removed from the system.

Therefore, we created different packages for the different categories of modules, like \textit{check} and \textit{version} plus some utility packages like \textit{parsing}, \textit{output} and \textit{mapping}.

The scopes for the different packages are the following:

\begin{itemize}
  \item \textit{check}: it aggregates the different controls on a property of the device, like the \textit{Check correct time} or the \textit{Check VNC credentials};
  \item \textit{version}: contains the modules to determine whether the software running on the device is up-to-date or not;
  \item \textit{parsing}: it handles the parsing of the input parameters, for example the verbose flag or the list of checks to run;
  \item \textit{output}: it manages the output of the checks, like the output format and the output file;
  \item \textit{mapping}: contains the effective available mapping for the tool.
  \item \textit{variab} and \textit{utils}: are utility packages that contain some common structures and functions that are used across the codebase.
\end{itemize}

The structure of a module is composed by the actual interface, named as \textit{<module>Interface}, where \textit{<module>} is the name of the module, a struct that implements the interface, named as \textit{<module>Struct} and a function that returns an instance of the struct, named as \textit{new<Module>}.
All the fields of the struct are private, and the public method is the one that returns the method of the interface.

A practical example is the \textit{CheckTime} module, that checks if the time of the device is correct. The interface is defined as follows:

\begin{lstlisting}[style=golang]
type checkTimeInterface interface {
	checkTime(context.Context) variab.Result
	getNtpHmiConfig(context.Context) (*hmiDateTimeDto, error)
	getRealTimeWrapper() (*time.Time, error)
}
\end{lstlisting}

The struct is defined as follows:

\begin{lstlisting}[style=golang]
type checkTimeStruct struct {
	delta             time.Duration
	getCliTime        func() (*string, error)
	getRealTime       func(string, string, string, time.Duration) (*time.Time, error)
	[omitted]
	timeout           time.Duration
}
\end{lstlisting}

There is an instance of the struct that is returned by the function \textit{newCheckTime}:

\begin{lstlisting}[style=golang]
func newCheckTime() checkTimeInterface {
	return &checkTimeStruct{
		delta:          DELTA_DURATION,
		getCliTime:     getCliTime,
		getRealTime:    getRealTime,
		[omitted]
		timeout:        utils.TIMEOUT,
	}
}
\end{lstlisting}

and the public method is the one that returns the method of the interface:

\begin{lstlisting}[style=golang]
var checkTime checkTimeInterface = newCheckTime()

func CheckTime(ctx context.Context) variab.Result {
	return checkTime.checkTime(ctx)
}
\end{lstlisting}

% Some of the variables are omitted for brevity. The other ones come from both some constants and some utility variables defined accross the codebase. 
The interface has a method that checks if the time of the device is correct, and it returns a \textit{variab.Result} struct that contains the result of the check.

The \textit{Result} structure of the package \textit{variab} is a common structure that is used to return the result of the checks. It contains the a concise message for the output, an optional recommendation to solve the issue, a severity level ranging from \textit{none} to \textit{high} and an operation status, where \textit{OK} means that the module completed the task without noticing any vulnerability, \textit{ISSUE} means that the module contains a potential weakness, \textit{EXECUTION\_ERROR} in the case of a unhandled exception, \textit{UNKNOWN} otherwise. This structure is used by all the modules to return the result of a module.

\begin{lstlisting}[style=json, caption={Result struct}]
{
  "message": string,
  "recommendation": string,
  "severity": none|low|moderate|high,
  "status": OK|ISSUE|EXECUTION_ERROR|UNKNOWN
}
\end{lstlisting}

This composition is common to all the modules, and it allows to easily test the modules in isolation, by mocking the dependencies of the struct. This is done by creating a new struct that implements the same interface, but with mocked methods, and then injecting this struct in the test. This way, we can test the module without having to actually run the code that is being mocked. This is a powerful feature of the Go language that allows to write more robust and maintainable code. More to follow about the testing phase in the next chapter.

\section{First sprint}

The first sprint has the goal to implement the first set of modules, as expressed in the sprint planning.

\subsection{CheckTime module}

The \textit{CheckTime} module checks if the datetime of the device is correct. This is a fundamental thing to verify because the issues with the devices not connecting to the internet and to the cloud are most of the time due to the incorrect datetime, leading to an error with the SSL certificate. In fact, if the date is not correct, the SSL certificate could result as expired or not yet valid, warning the user that the connection is not secure.

It does so by getting the time from the device and the real time from a remote server, and then comparing the two times. If the difference between the two times is greater than a certain threshold, expressed in a range of few minutes, then the module returns an \textit{ISSUE} status, otherwise it returns an \textit{OK} status. Of course, this module works with an active internet connection only; if the device is not connected to the internet, then the module returns a valid execution error.

To perform the execution, it runs the following steps:
\begin{itemize}
  \item first, it gets the UNIX timestamp, a integer number representing the elapsed seconds since 1\textsuperscript{st} January 1970, by executing the command \texttt{date +\%s} on the local shell;
  \item then it calls a remote endpoint that returns the real datetime;
  \item it parses the two datetimes;
  \item finally, it compares their difference and returns the result.
\end{itemize}

If any of the steps fails, the module returns the execution error status.

% proxy network call qui?

\subsection{JSON output}
\label{sec:json-output}

Every module returns a structure representing the result of the execution, a brief message and a recommendation to solve the potential issue. The modules runner collects all the results from the modules in a \textit{Report} type variable, that is defined as a map of maps, in order to have the direct mapping of the result of the module under the category and the name of the module.

The resulting type is therefore given to the output package, which is responsible for the output of the results in the desired format. The default formatter is JSON, but it can be easily extended to support other formats like YAML by importing or implementing the corresponding marshaler, that is a function that transforms the encoding of an \textit{any} value to the desired format.

By default, the output is printed to the standard output of the terminal, but the destination can be redirected to a file by using the built-in method with the \texttt{-o} flag. The output can be printed in a pretty format by using the \texttt{--pretty} flag, useful for human readability. Anyway, the predefined formatting is minified.

The formatter can be choosen by using the \texttt{-o} flag, followed by the desired format.

The list of the active modules is available with the command \texttt{./scantool list}, printed in the standard output of the terminal, one for line.

For example, given the execution of the datetime module only, issued with the command \texttt{./scantool scan -l "check.time" --pretty} with no further parameters, the output could be the following:

\begin{lstlisting}[style=json, caption={Output of the datetime module}]
{
"check": {
  "time": {
    "message": "The current datetime is synced",
    "recommendation": "No action required",
    "severity": "none",
    "status": "OK"
  }
}
\end{lstlisting}

\subsection{Cross build script}

The Go programming language provides a powerful feature called cross-compilation. This allows to build the binary for a different architecture than the one of the machine that is building it. This is useful to build the binary for a different architecture, like ARM, that is the architecture of some of the devices that we are going to use for debugging purposes.

Go provides the built-in command \texttt{go build <file>} that builds the binary for the current architecture, but it also provides the \texttt{GOOS} and \texttt{GOARCH} environment variables that can be set to the desired values to build the binary for a different architecture.

The former is the operating system, and the latter is the architecture. Possible values useful for the project are \texttt{linux} for the operating system and \textit{arm}, \textit{arm64} and \textit{amd64} for the architecture. All the available values can be found in the official documentation of the Go programming language.~\cite{go-valid-goos-goarch-combinations}

By default, the binary includes debug symbols, that are useful for debugging purposes, but they are not necessary for the production environment. They increase the size of the binary of several megabytes, and they are not needed for the end user. In particular, we add two flags to the build command:~\cite{go-ldflags-all,go-ldflags-s-w}
\begin{itemize}
  \item \texttt{-s} turns off generation of the Go symbol table;
  \item \texttt{-w} turns off debugging information, not being able to trace the resulting binary with the \texttt{gdb} debugger.
\end{itemize}

In the context of the automatic pipeline that builds the binary for the different architectures, we also inject the version number of the binary in the build command, by using the \texttt{-X importpath.name=value} flag. This flag allows to set the value of the string variable in \textit{importpath} named name to \textit{value}.~\cite{go-ldflags-all}

Furthermore, we also explicitly set the environment variable \texttt{CGO\_ENABLED=0} to disable the use of the machine C compiler. Anyway, that is disabled by default when cross-compiling and the go builder chooses the appropriate compiler for the target architecture.~\cite{go-cgo-compiler}

Finally, we set the \texttt{-trimpath} flag to remove the absolute path of the source files from the binary, in order to make the binary reproducible. This is a good practice to follow, as it does not leak any information about the source code and the environment where the binary was built.~\cite{go-trimpath-arg}

The resulting binary for each architecture is placed in a tree of directory, where the root directory is the version of the binary, and the subdirectories are the architectures. The filename of the binary is the same as the name of the project, that is \texttt{scantool}.

The final build command is the following:
\begin{lstlisting}[caption={Go tool cross-build command}]
  env GOOS=$GOOS GOARCH=$GOARCH CGO_ENABLED=0 go build -trimpath -ldflags="-s -w -X 'main.VERSION=$version'" -o $output_base_dir/$version/$arch/$filename main.go
\end{lstlisting}

The difference between the size of a build without any optimization and a optimized build is quite relevant. Taking as example the architecture \textit{arm64} on the \textit{Linux} operating system, the former takes 12MB and the latter takes 7.7MB. On industrial devices, such size difference matters a lot in terms of storage and used bandwidth to download it on the fly when needed.

\subsection{Scan OS version}

The custom board of the industrial devices powers a custom Linux distribution, that is based on the Yocto Project. The updates are managed by the internal department of the company, with a internal version manager. The updates are not automatic, and they have to be requested by the customer.

This module monitors whether the operating system is at its latest version or not. Given that the estimated work to implement it as a single block is not trivial, we can split it into two different specializations: the first one is the one that checks the version of the operating system by retrieving the build date, and the second one is the one that checks the version of the operating system by reading the online repository.

The Device Settings API, a set of endpoints used to retrieve the information about the status of the device and to potentially change them, provides among other things the version number and the build date of the operating system. There is the \texttt{/api/v1/management/mainos} endpoint that returns a JSON object structured as follows:

\begin{lstlisting}
{
  "version": "4.2.323",
  "date": "2024-04-17T06:00:00.000Z"
}
\end{lstlisting}

The module is implemented by the \textit{versionOsInterface} and \textit{versionOsStruct} structure. The interface is defined as:

\begin{lstlisting}[style=golang]
type versionOsInterface interface {
  getOsInfo(context.Context) (*versionOsApiDto, error)
  checkOsVersion(context.Context) variab.Result
}
\end{lstlisting}

and the structure is composed by the following fields:

\begin{lstlisting}[style=golang]
type versionOsStruct struct {
  xMonthAgo      int
  [omitted]
}
\end{lstlisting}

The \textit{xMonthAgo} field is the threshold expressed in a range of few months. The \textit{getOsInfo} method retrieves the information about the operating system from the Device Settings API, and the \textit{checkOsVersion} method actually perform the comparison.

\subsubsection{Offline date based}

The first specialization of the module checks the version of the operating system by reading the build date of the system. This is done by retrieving the build date of the system from the Device Settings API, that is the \textit{date} field of the API response. The date is then compared with the current date, and if the difference is greater than a certain threshold then the module returns an issue, otherwise it returns an OK status throug the \textit{Result} structure.

\subsubsection{Online version based}

This specialization should compare the local version of the operating system with the latest version available somewhere online. Since the company does not provide a public repository for the updates, this module cannot be implemented yet. The idea is to have a list of the latest versions for the different devices models and to compare the local version with the latest one. If the local version is not updated, then the module returns an issue, otherwise it returns an OK status. This is a future work that can be implemented when the company will provide a public repository for the updates. As a matter of fact, this story has been suspended in the context of our project.

\subsection{Default BSP credentials}

Setting common passwords is a bad practice, as they let an attacker to potentially gain unauthorized access to the management of the device.

The devices ship with some default credentials for the two users that are available on the system, named \textit{admin} and \textit{user}. The credentials are required to interact with the Device Settings. They are asked to be changed at the first login, but the user could skip the step and keep the default ones.\footnote{verify}

The module checks whether the default credentials are still in use by trying to login with a pre-defined set of passwords on the two users. The module performs $2*|passwords|$ HEAD requests to an arbitrary endpoint of the Device Settings API and it checks the status code of the response. If one of the responses' status code is \textit{200 Success}, meaning that the authorization has been granted and therefore username and password match, then the module returns an issue with a high severity, otherwise it returns an OK status.

This security control is possible without stumbling into the device built-in authentication rate-limiting because the total number of requests is below the threshold of the requests for minute that the device accept before temporarily blocking the access from that access.

The module is implemented by the \textit{checkCredentialsSystemSettingsInterface} and \textit{checkCredentialsSystemSettingsStruct} structure. The interface is defined as:

\begin{lstlisting}[style=golang]
type checkCredentialsSystemSettingsInterface interface {
	checkCredentialsSystemSettings(context.Context) variab.Result
}
\end{lstlisting}

and the structure is made of the following fields:

\begin{lstlisting}[style=golang]
type checkCredentialsSystemSettingsStruct struct {
  [omitted]
  hmiHeadRequest func(string, time.Duration, *string, *string) (*http.Response,error)
  users          []string
  passwords      []string
}
\end{lstlisting}

The \textit{hmiHeadRequest} function is a utility function that performs a HEAD request to the given URL with a certain user and password. The \textit{users} and \textit{passwords} fields are the list of users and passwords to try to login with.

\subsection{Scan SSH port}

The SSH protocol, which stands for \textit{Secure Shell}, is a cryptographic network protocol that allows to securely connect to a remote device. It is widely used in the industry to connect to the devices for the purposes of debugging, maintenance and monitoring. The SSH protocol is based on the client-server model, where the client connects to the server and authenticates itself by providing a username and a password or a public key. The server then verifies the credentials and grants access to the client if they are correct.

The SSH protocol is based on the TCP protocol, and it uses the port 22 by default. The server, that is the industrial device, listens on the port 22 for incoming connections. Because of the widespread adoption of the SSH protocol, that port is a common target for attackers that try to gain unauthorized access to the devices.

This story is a specialization of a wider set of stories that check the status of the different services running on the device. The idea is to check whether the status of the service reported by the Device Settings API matches with the actual status of the service, and if enabled to warn that a port is exposed and therefore to be informed about the potential risks.

The module is implemented by the \textit{checkServicesInterface} and \textit{checkServicesStruct} structure. The interface is defined as:

\begin{lstlisting}[style=golang]
type checkServicesInterface interface {
  checkServices(context.Context, string) variab.Result
  hmiConfig() (*hmiServicesDto, error)
}
\end{lstlisting}

and the structure is composed by the following fields:

\begin{lstlisting}[style=golang]
type checkServicesStruct struct {
  isPortOpen     func(uint, time.Duration) (bool, error)
  [omitted]
}
\end{lstlisting}

The \textit{hmiConfig} function retrieves the information about the services from the Device Settings API, and the \textit{checkServices} function actually performs the check. The API endpoint is located at \texttt{/api/v1/services} and it returns a JSON object structured as a list of object for each service, where each object contains its id, the name and the status.

The \textit{isPortOpen} function is a utility function that checks if the port is open on the device. It works by trying to connect to the device on the port defined by a predefined map that contains a list of possible ports for each of the services. Depending on the protocol, the function tries to connect to each of the ports and returns true if the connection is successful, otherwise it returns false.

By combining the two functions, the module checks if the SSH port status reported by the Device Settings API matches with the actual status of the port.

\subsection{Check VNC credentials}

As part of the services that are running on the device, one of them is the VNC service. VNC, which stands for \textit{Virtual Network Computing}, is a cross-platform graphical desktop sharing system to remotely control another computer. It transmits the screen of the remote device to the client, and it allows to interact with it by sending the mouse and keyboard events. It uses the RFB - \textit{Remote Framebuffer} - protocol that governs the format of the data that passes between the client and server within the VNC system. The protocol itself does not require a mandatory authentication method, but is supports many of them, like a password or a certificate.

If the service is not properly configured and it does not require a password to connect, then an attacker could potentially gain unauthorized direct access to the graphical interface and perform any operation that a legitimate user could do.

The module checks whether the VNC service is configured with a password or not. It does so by retrieving the configuration, in particular the port on which the service is running, from the Device Settings API, and then implementing the protocol itself to get the required authentication method. If the authentication method is not set, then the module returns an issue with a high severity, otherwise it returns an OK status.

\subsubsection{RFB protocol}

The RFB protocol is defined in the RFC 6143~\cite{rfc6143}. It works using the TCP protocol for the transport layer. The server, that is the industrial device, listens on the default port 5900 or on a custom one defined by the customer in the Device Settings.

The protocol expects the following steps:

\begin{enumerate}
  \item the client connect to the server and the server sends the protocol version; the \textit{ProtocolVersion} message consists of 12 bytes interpreted as a string of ASCII characters in the format \texttt{RFB xxx.yyy\textbackslash n} where xxx and yyy are the major and minor version numbers, left-padded with zeros: the only published protocol versions at this time are 3.3, 3.7, and 3.8. Other version numbers are reported by some servers and clients, but should be interpreted as 3.3 since they do not implement the different handshake in 3.7 or 3.8.
  \item the client replies to the server agreeing with its supported version, that must be less or equal to the one of the server;
        \begin{itemize}
          \item if the version is 3.3, then the server directly replies with a single integer number representing the security type;
          \item otherwise, the server replies with a list of numbers representing the security types that the server supports;
        \end{itemize}
  \item at this point, instead of proceeding with the protocol, we close the connection and we return the security type.
\end{enumerate}

If the security type is equal to the number 1, the server does not require any authentication. If the number is equal to 0, this is not expected and probably something went wrong in the implementation of the protocol. Both cases return as result a high severity issue. \\
If the security type is greater or equal to number 2, then the server correctly requires some access control. Note that we said greater than two and not strictly equal to 2 because other security types exist but are not publicly documented.

\begin{figure}[h]
  \centering
  \includegraphics[width=0.5\textwidth]{chapters/05/assets/rfc6143-security-types}
  \caption{RFC 6143 security types}
  \label{fig:rfc6143-security-types}
\end{figure}

The module is implemented by the \textit{checkVncCredentialsInterface} and \textit{checkVncCredentialsStruct} structure. The interface is defined as:

\begin{lstlisting}[style=golang]
type checkCredentialsVNCInterface interface {
	checkCredentialsVNC(context.Context) variab.Result
}
\end{lstlisting}

and the structure is composed by the following fields:

\begin{lstlisting}[style=golang]
type checkCredentialsVNCStruct struct {
  [omitted]
  vncConn               func(string, time.Duration) (bool, net.Conn)
  vncProtocolVersion    func(net.Conn) ([]byte, error)
  vncAuthType3          func(net.Conn) (uint32, error)
  vncAuthType7_8        func(net.Conn) (uint32, error)
}
\end{lstlisting}

The \textit{vncConn} function create the connection to the VNC server, the \textit{vncProtocolVersion} function retrieves the protocol version, the \textit{vncAuthType3} function retrieves the authentication method for the version 3 of the protocol, and the \textit{vncAuthType7\_8} function retrieves the authentication method for the versions 7 and 8 of the protocol.

The \textit{checkCredentialsVNC} function performs the check by combining the functions above.

\subsection{Check certificate expiration}

The device uses the HTTPS protocol to expose the Device Settings UI and API and the optional web page of the running project. The HTTPS protocol is a secure version of the HTTP protocol that uses the SSL/TLS protocol to encrypt the data that passes between the client and the server. The SSL/TLS protocol uses a certificate to establish the identity of the server and to encrypt the data that passes between the client and the server. This behaviour is needed to prevent an attacker from intercepting the data that passes between the client and the server.

The certificate is issued by the company authority and it is valid for a certain period of time, usually years. A customer can upload a custom certificate to the device. The certificate is stored in the device.

The module checks whether the certificate is expired or not. Go provides built-in packages called \texttt{encoding/pem} and \texttt{crypto/x509} that allow to parse the certificate and to extract the expiration date. The former implements the PEM data encoding, which originated in \textit{Privacy Enhanced Mail}. The most common use of PEM encoding today is in TLS keys and certificates~\cite{go-package-pem}. The latter allows parsing and generating certificates, certificate signing requests, certificate revocation lists, and encoded public and private keys. It also provides a certificate verifier with a chain builder~\cite{go-package-x509}.

In particular, the certificate is read as bytes from the file system, then it is parsed by the \texttt{pem.Decode} function that returns a \texttt{pem.Block} structure. The \texttt{Block} structure contains the type of the block and the bytes of the block. The bytes are then passed to the \texttt{x509.ParseCertificate} function that returns a \texttt{x509.Certificate} structure. The \texttt{Certificate} structure also contains the expiration date of the certificate.

The expiration date is then compared with the current date: if the expiration date happens in less than 30 days, the the module returns an issue. If the valid days left are less than 30, the severity is low; if they are less than 15, the severity is moderate; if they are less than 1, the severity is high.

The implementation of the module is defined by the \textit{checkCertificatesInterface} and \textit{checkCertificatesStruct} structure. The interface looks like:

\begin{lstlisting}[style=golang]
type checkCerticatesInterface interface {
	checkCertificates(context.Context) variab.Result
}
\end{lstlisting}

and the structure is composed by the following fields:

\begin{lstlisting}[style=golang]
type checkCertificatesStruct struct {
	hmiCertPath string
	loadCertFile func(string) ([]byte, error)
}
\end{lstlisting}

The \textit{hmiCertPath} field is the path to the certificate file, and the \textit{loadCertFile} function reads the certificate file from the file system. The \textit{checkCertificates} function performs the check by combining the functions above.

\subsection{Verbose flag}

This flag is a common one that is used in the command line interface of the tool to increase the verbosity of the output. By default, the output is minimal and it contains only the result of the checks, but by using the \texttt{--verbose} flag the output is increased to include more information about the execution of the modules.

The flag is implemented taking advantage of the hooks provided by \textit{spf13/cobra}, that is the package that we use to implement the command line interface. The \texttt{cobra.Command} structure provides a \texttt{PersistentPreRun} callback that is called before the execution. We use this callback to set the verbosity level of the output for the \textit{zerolog} package with the \texttt{zerolog.SetGlobalLevel} function.

This flag is defined as persistent, meaning that it is available for every commands and subcommands and it only defined once.

\subsection{Add YAML report formatter}

In addition to the JSON output, we also add the YAML output format. The YAML format is a human-readable data serialization standard that can be used in conjunction with all programming languages and is often used to write configuration files. The YAML format is more human-readable than the JSON format. It is not built-in in the Go programming language, but there is an official porting available at the \texttt{gopkg.in/yaml.v3} package.

As described in~\cref{sec:json-output}, the output package is responsible for the output of the results in the desired format. The default format is JSON, but it can be easily extended to support other formats like YAML by importing the corresponding marshaler.

In this case, we add the \texttt{yaml.Marshal} function to the output package the \textit{Report} structure. If the user specifies the \texttt{-o yaml} flag, then the output is formatted in YAML to the desidered destination.

The high modularity of the Go language and of the project allows to easily extends the output formats by simply adding few lines of code. This is a powerful feature of the Go language that allows to write more maintainable code.

\section{First sprint retrospective}

The first sprint has been completed successfully. All the expected modules but one have been implemented. For each of the tests we have written comprehensive unit tests that runs on demand. The implementation of the modules has been straightforward. The use of the interfaces has allowed to easily test the modules in isolation, by mocking the dependencies of the struct.

The only module that has not been implemented is the one that checks the version of the operating system by reading the online repository. This is because the company does not provide a public repository for the updates, and therefore we cannot implement the module yet. This is a future work that can be implemented when the company will provide a public repository for the updates.

% TODO: sezione testing
% The implementation of the modules has been done in a test-driven way. We have written the tests first, and then we have implemented the modules.

Given that the first sprint has been completed successfully, we can move on to the second sprint. We did a meeting to show the results of the sprint to the office and to discuss the next steps. The feedback has been positive, and the team is happy with the results. The next sprint focuses on the implementation of more server side utilities and some more modules.

\section{Second sprint}

The second sprint has the goal to implement the following set of modules:

\begin{itemize}
  \item Create cloud app
  \item Implement proxy network call
  \item Automatic build and deploy
  \item Enable to download latest version of the tool
  \item Support internationalization
\end{itemize}

These are new features useful for the future adoption of the tool in the company.

The first two are server side utilities that are needed to prepare the infrastructure for future development of the tool in terms of strictly network policies and user billing. In fact, the company is interested in the possibility to offer the tool as a service to the customers, and therefore it is necessary to have a server side application in order to handle the functioning. Furthermore, as previously said, industrial network policies are very strict and usually they do not allow to connect directly to the internet, and therefore a proxy is needed to perform the network calls. \\
For example, given the case of a version check, if the remote location on which the version is stored happens on a third-party endpoint, like for a external dependency, each network administrator for each customer should manually allow the connection to that location, and beforehand the company should provide the list of the locations to allow and keep it updated. In order to avoid this, the company can provide a proxy server that is the only one that connects to the internet. The tool can then connect to the proxy server. This way, network administrators only have to allow the connection to the proxy server, that is already expected for the standard operation of the device.

The second and third points are about the automatic build and deploy of the tool. The company is interested in the possibility to automatically build the tool for the different architectures and to deploy it on the devices. This is also useful for testing purposes, as the build is preceded by the execution of the tests and also for the continuous integration and continuous deployment of the tool.

The latest point aims to provide the internationalization, that is the support for different languages. The company is interested in the possibility to offer the tool in different languages, in order to make it more accessible to the customers.

\subsection{Create cloud app}

Recalling~\cref{sec:platform-applications}, the cloud app is an entire runtime made by a frontend and a backend that is visible through the platform website. The frontend is a VueJS application and the backend uses NestJS as framework for handling the controllers, the models and the logic. Both the frontend and the backend are written in TypeScript and both implement the authentication with the platform, as it is really integrated with the platform itself and cannot be used in a standalone mode.

The skeleton of the application is generated by a public utility developed by the company, which is available on the public NPM registry. This utility generates the boilerplate code for the frontend and the backend, with many features already implemented, like the authentication with the platform, basic routing, controllers and models needed to complete the first installation on the platform.

The app also provides a running configuration of \textit{PostgreSQL} database that is used to store its data. The database is also deployed on the Kubernetes cluster.

The application has to be deployed on a Kubernetes cluster. The code also contains the required charts files, personalized for the application, that are used by the Helm package manager to deploy the application on the cluster, and the Dockerfile that is used to build the Docker image of the application.

Once the deployment is live on the cluster, the application can be linked to the platform store by using the public REST API of the platform. Doing so, the application is visible on the platform website and it can be accessed by the customers.

\subsection{Implement proxy network call}

As said, usually the industrial networks attached to the devices are very strict and do not allow to communicate with every host on the internet. This is a security measure that is taken to reduce the risks of exposing a relatively weak devices. In fact, unfortunately the devices are usually not updated frequently by the customers and they are not patched for the latest vulnerabilities. The goal of the tool described in this thesis is also to make aware the customers of a potential vulnerability that could be exploited by an attacker and new avaiable updates. In order to do so, the tool has to communicate with the internet to check the latest version of the software. How to do that given all the constraints?

The solution we thought is to provide a proxy server that is the only one that connects to the final endpoints. The tool can then connect to the proxy server. This way, network administrators only have to allow the connection to the proxy server, that is already expected for the standard operation of the device.

The proxy server is managed by a controller on the cloud app backend. The controller is responsible for handling the incoming requests from the tool and for forwarding them to the respective methods. The controller is also responsible for handling the authentication with the platform. It is written in TypeScript and it uses the NestJS framework.

The proxy controller is a class that it is decorated with the \texttt{@Controller} decorator, that is provided by the NestJS framework, with the parameter that is the base path of the controller. A decorator is a special kind of declaration that can be attached to a class, method or property, and it is used to modify their behaviour. The class is also decorated with \texttt{@ApiTags}, needed to generate the OpenAPI documentation, and by a \texttt{@UseInterceptors} directive with the \textit{LoggingInterceptor} custom one that logs the incoming requests. \\
The class contains the declaration of the services that are used by the controller to perform the actual operations. The services are injected in the constructor of the class. The class also contains the methods that are the actual endpoints of the controller. The methods are decorated with the \texttt{@Get}, \texttt{@Post}, \texttt{@Put} or \texttt{@Delete} decorators, depending on the HTTP method that they handle. The methods also contain the logic to handle the incoming requests and to return the responses. The responses are returned in the form of specific \textit{DTO}s, which stands for \textit{data transfer object} and it is a object that carries data between processes, automatically serialized by the NestJS framework to the JSON format.





